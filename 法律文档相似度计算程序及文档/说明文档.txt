一、分词程序：
输入：按首部等切割后的文档所在文件夹名   分词后文档存放的文件夹名
输出：分词后的法律文档，保存在相应的文件夹

运行命令：
python    jieba_seg.py     split_case     split_seg_case
# 其中split_case为切割后的法律文档所在文件夹   split_seg_case为分词后的文件夹
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
二、法律文档相似度计算程序：
输入：需查询相似文件的文件（已分词）所在文件夹名（test_path）      相似文件（已分词）的来源（文件夹名）(train_path)     相似文件的个数（top_k）
输出：对于每个文件，找出与其最相似的top_k个文件，将其文件名保存在sim_file.txt中

程序简要说明：
1.首先解析用户所输参数
2.读取test_path和train_path中的文件，根据关键字得到计算相似度所需的部分，统计各文档的词频特征；
3.将词频特征转化为tfidf特征
4.对于每个查询文件，计算其与train_path中文档的相似度（余弦相似度），返回最相似的top_k个文档；
5.将结果保存（sim_file.txt）。

运行命令：
python    cal_similarity.py    test_path train_path    top_k

eg. python    cal_similarity.py    test_path    split_seg_case    3

原始语料下载：http://download.csdn.net/detail/u013303789/9765344